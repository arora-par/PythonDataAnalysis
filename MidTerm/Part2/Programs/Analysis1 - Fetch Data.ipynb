{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Data - New York Times - Article Search API - Sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of the environment variable for api-key:  d813d3ec9be6406a904efa4ce9589c82\n"
     ]
    }
   ],
   "source": [
    "nyt_api_key = os.getenv('NYT_API_KEY')\n",
    "articlesearch_url = 'https://api.nytimes.com/svc/search/v2/articlesearch.json'\n",
    "print('Value of the environment variable for api-key: ', nyt_api_key) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define all the functions needed to carry out the download process dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createdir(filename):                           # funtion to create directory if not exists\n",
    "    dirname=os.path.dirname(filename)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveDocs(folderName, page, docs):             # funtion to save downloaded data\n",
    "    for doc in docs:\n",
    "        pub_datetime_str = doc['pub_date']\n",
    "        pub_datetime = datetime.strptime(pub_datetime_str[0:19], \"%Y-%m-%dT%H:%M:%S\")\n",
    "        month_name = pub_datetime.strftime(\"%b\")\n",
    "        \n",
    "        finalfilepath = '../Data/NYT/Sports/' + folderName + '/' + month_name + '/' + doc['_id'] + '.json'\n",
    "        createdir(finalfilepath)\n",
    "        with open(finalfilepath, 'w') as open_file:\n",
    "            json.dump(doc, open_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the primary function that starts the whole process\n",
    "def downloadData(url, reqparams, destFolder):\n",
    "    remaining_pages = downloadFirstPage(url, reqparams, destFolder)\n",
    "    downloadRemainingPages(url, reqparams, remaining_pages, destFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First request\n",
    "def downloadFirstPage(url, reqparams, destFolder):\n",
    "    r = requests.get(url, params = reqparams)\n",
    "    if r.status_code == 200:\n",
    "        jsonObj = json.loads(r.text)\n",
    "        # save docs from current request\n",
    "        saveDocs(destFolder, page = 0, docs = jsonObj['response']['docs'])\n",
    "        # get total hits to prepare for dynamically getting remaining docs\n",
    "        hits = jsonObj['response']['meta']['hits']\n",
    "        remaining_pages = int(hits / 10)\n",
    "        if hits % 10 == 0:\n",
    "            remaining_pages = remaining_pages - 1\n",
    "    else:\n",
    "        print('Error downloading first page', r.text)\n",
    "    print('Remaining pages:', remaining_pages)\n",
    "    return remaining_pages\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download documents from remaining_pages\n",
    "def downloadRemainingPages(url, reqparams, remaining_pages, destFolder):\n",
    "    for page_number in range(1, remaining_pages + 1):\n",
    "        if page_number % 5:\n",
    "            # API restriction: sleep 1 sec after every 5 request \n",
    "            time.sleep(1)\n",
    "        reqparams['page'] = page_number\n",
    "        r = requests.get(url, params = reqparams)\n",
    "        if r.status_code == 200:\n",
    "            jsonObj = json.loads(r.text)\n",
    "            # save docs from current request\n",
    "            saveDocs(destFolder, page = page_number, docs = jsonObj['response']['docs'])\n",
    "        else:\n",
    "            print('Error downloading page:', page_number, r.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining pages: 48\n",
      "Requesting info for page: 1\n",
      "Got results for page: 1.0\n",
      "Requesting info for page: 2\n",
      "Got results for page: 2.0\n",
      "Requesting info for page: 3\n",
      "Got results for page: 3.0\n",
      "Requesting info for page: 4\n",
      "Got results for page: 4.0\n",
      "Requesting info for page: 5\n",
      "Got results for page: 5.0\n",
      "Requesting info for page: 6\n",
      "Got results for page: 6.0\n",
      "Requesting info for page: 7\n",
      "Got results for page: 7.0\n",
      "Requesting info for page: 8\n",
      "Got results for page: 8.0\n",
      "Requesting info for page: 9\n",
      "Got results for page: 9.0\n",
      "Requesting info for page: 10\n",
      "Got results for page: 10.0\n",
      "Requesting info for page: 11\n",
      "Got results for page: 11.0\n",
      "Requesting info for page: 12\n",
      "Got results for page: 12.0\n",
      "Requesting info for page: 13\n",
      "Got results for page: 13.0\n",
      "Requesting info for page: 14\n",
      "Got results for page: 14.0\n",
      "Requesting info for page: 15\n",
      "Requesting info for page: 16\n",
      "Got results for page: 16.0\n",
      "Requesting info for page: 17\n",
      "Got results for page: 17.0\n",
      "Requesting info for page: 18\n",
      "Got results for page: 18.0\n",
      "Requesting info for page: 19\n",
      "Got results for page: 19.0\n",
      "Requesting info for page: 20\n",
      "Requesting info for page: 21\n",
      "Got results for page: 21.0\n",
      "Requesting info for page: 22\n",
      "Got results for page: 22.0\n",
      "Requesting info for page: 23\n",
      "Got results for page: 23.0\n",
      "Requesting info for page: 24\n",
      "Got results for page: 24.0\n",
      "Requesting info for page: 25\n",
      "Got results for page: 25.0\n",
      "Requesting info for page: 26\n",
      "Got results for page: 26.0\n",
      "Requesting info for page: 27\n",
      "Got results for page: 27.0\n",
      "Requesting info for page: 28\n",
      "Got results for page: 28.0\n",
      "Requesting info for page: 29\n",
      "Got results for page: 29.0\n",
      "Requesting info for page: 30\n",
      "Requesting info for page: 31\n",
      "Got results for page: 31.0\n",
      "Requesting info for page: 32\n",
      "Got results for page: 32.0\n",
      "Requesting info for page: 33\n",
      "Got results for page: 33.0\n",
      "Requesting info for page: 34\n",
      "Got results for page: 34.0\n",
      "Requesting info for page: 35\n",
      "Got results for page: 35.0\n",
      "Requesting info for page: 36\n",
      "Got results for page: 36.0\n",
      "Requesting info for page: 37\n",
      "Got results for page: 37.0\n",
      "Requesting info for page: 38\n",
      "Got results for page: 38.0\n",
      "Requesting info for page: 39\n",
      "Got results for page: 39.0\n",
      "Requesting info for page: 40\n",
      "Requesting info for page: 41\n",
      "Got results for page: 41.0\n",
      "Requesting info for page: 42\n",
      "Got results for page: 42.0\n",
      "Requesting info for page: 43\n",
      "Got results for page: 43.0\n",
      "Requesting info for page: 44\n",
      "Got results for page: 44.0\n",
      "Requesting info for page: 45\n",
      "Requesting info for page: 46\n",
      "Got results for page: 46.0\n",
      "Requesting info for page: 47\n",
      "Got results for page: 47.0\n",
      "Requesting info for page: 48\n",
      "Got results for page: 48.0\n"
     ]
    }
   ],
   "source": [
    "# Request Map for Celtics\n",
    "reqparams = {'api-key':nyt_api_key, 'q':'Boston Celtics','begin_date':'20160101', 'end_date':'20161231'}\n",
    "downloadData(articlesearch_url, reqparams, 'Boston Celtics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining pages: 85\n",
      "Requesting info for page: 1\n",
      "Got results for page: 1.0\n",
      "Requesting info for page: 2\n",
      "Got results for page: 2.0\n",
      "Requesting info for page: 3\n",
      "Got results for page: 3.0\n",
      "Requesting info for page: 4\n",
      "Got results for page: 4.0\n",
      "Requesting info for page: 5\n",
      "Requesting info for page: 6\n",
      "Got results for page: 6.0\n",
      "Requesting info for page: 7\n",
      "Got results for page: 7.0\n",
      "Requesting info for page: 8\n",
      "Got results for page: 8.0\n",
      "Requesting info for page: 9\n",
      "Got results for page: 9.0\n",
      "Requesting info for page: 10\n",
      "Got results for page: 10.0\n",
      "Requesting info for page: 11\n",
      "Got results for page: 11.0\n",
      "Requesting info for page: 12\n",
      "Got results for page: 12.0\n",
      "Requesting info for page: 13\n",
      "Got results for page: 13.0\n",
      "Requesting info for page: 14\n",
      "Got results for page: 14.0\n",
      "Requesting info for page: 15\n",
      "Requesting info for page: 16\n",
      "Got results for page: 16.0\n",
      "Requesting info for page: 17\n",
      "Got results for page: 17.0\n",
      "Requesting info for page: 18\n",
      "Got results for page: 18.0\n",
      "Requesting info for page: 19\n",
      "Got results for page: 19.0\n",
      "Requesting info for page: 20\n",
      "Requesting info for page: 21\n",
      "Got results for page: 21.0\n",
      "Requesting info for page: 22\n",
      "Got results for page: 22.0\n",
      "Requesting info for page: 23\n",
      "Got results for page: 23.0\n",
      "Requesting info for page: 24\n",
      "Got results for page: 24.0\n",
      "Requesting info for page: 25\n",
      "Got results for page: 25.0\n",
      "Requesting info for page: 26\n",
      "Got results for page: 26.0\n",
      "Requesting info for page: 27\n",
      "Got results for page: 27.0\n",
      "Requesting info for page: 28\n",
      "Got results for page: 28.0\n",
      "Requesting info for page: 29\n",
      "Got results for page: 29.0\n",
      "Requesting info for page: 30\n",
      "Got results for page: 30.0\n",
      "Requesting info for page: 31\n",
      "Got results for page: 31.0\n",
      "Requesting info for page: 32\n",
      "Got results for page: 32.0\n",
      "Requesting info for page: 33\n",
      "Got results for page: 33.0\n",
      "Requesting info for page: 34\n",
      "Got results for page: 34.0\n",
      "Requesting info for page: 35\n",
      "Got results for page: 35.0\n",
      "Requesting info for page: 36\n",
      "Got results for page: 36.0\n",
      "Requesting info for page: 37\n",
      "Got results for page: 37.0\n",
      "Requesting info for page: 38\n",
      "Got results for page: 38.0\n",
      "Requesting info for page: 39\n",
      "Got results for page: 39.0\n",
      "Requesting info for page: 40\n",
      "Requesting info for page: 41\n",
      "Got results for page: 41.0\n",
      "Requesting info for page: 42\n",
      "Got results for page: 42.0\n",
      "Requesting info for page: 43\n",
      "Got results for page: 43.0\n",
      "Requesting info for page: 44\n",
      "Requesting info for page: 45\n",
      "Requesting info for page: 46\n",
      "Got results for page: 46.0\n",
      "Requesting info for page: 47\n",
      "Got results for page: 47.0\n",
      "Requesting info for page: 48\n",
      "Got results for page: 48.0\n",
      "Requesting info for page: 49\n",
      "Got results for page: 49.0\n",
      "Requesting info for page: 50\n",
      "Got results for page: 50.0\n",
      "Requesting info for page: 51\n",
      "Got results for page: 51.0\n",
      "Requesting info for page: 52\n",
      "Got results for page: 52.0\n",
      "Requesting info for page: 53\n",
      "Got results for page: 53.0\n",
      "Requesting info for page: 54\n",
      "Got results for page: 54.0\n",
      "Requesting info for page: 55\n",
      "Requesting info for page: 56\n",
      "Got results for page: 56.0\n",
      "Requesting info for page: 57\n",
      "Got results for page: 57.0\n",
      "Requesting info for page: 58\n",
      "Got results for page: 58.0\n",
      "Requesting info for page: 59\n",
      "Got results for page: 59.0\n",
      "Requesting info for page: 60\n",
      "Got results for page: 60.0\n",
      "Requesting info for page: 61\n",
      "Got results for page: 61.0\n",
      "Requesting info for page: 62\n",
      "Got results for page: 62.0\n",
      "Requesting info for page: 63\n",
      "Got results for page: 63.0\n",
      "Requesting info for page: 64\n",
      "Got results for page: 64.0\n",
      "Requesting info for page: 65\n",
      "Requesting info for page: 66\n",
      "Got results for page: 66.0\n",
      "Requesting info for page: 67\n",
      "Got results for page: 67.0\n",
      "Requesting info for page: 68\n",
      "Got results for page: 68.0\n",
      "Requesting info for page: 69\n",
      "Got results for page: 69.0\n",
      "Requesting info for page: 70\n",
      "Got results for page: 70.0\n",
      "Requesting info for page: 71\n",
      "Got results for page: 71.0\n",
      "Requesting info for page: 72\n",
      "Got results for page: 72.0\n",
      "Requesting info for page: 73\n",
      "Got results for page: 73.0\n",
      "Requesting info for page: 74\n",
      "Got results for page: 74.0\n",
      "Requesting info for page: 75\n",
      "Requesting info for page: 76\n",
      "Got results for page: 76.0\n",
      "Requesting info for page: 77\n",
      "Got results for page: 77.0\n",
      "Requesting info for page: 78\n",
      "Got results for page: 78.0\n",
      "Requesting info for page: 79\n",
      "Got results for page: 79.0\n",
      "Requesting info for page: 80\n",
      "Got results for page: 80.0\n",
      "Requesting info for page: 81\n",
      "Got results for page: 81.0\n",
      "Requesting info for page: 82\n",
      "Got results for page: 82.0\n",
      "Requesting info for page: 83\n",
      "Got results for page: 83.0\n",
      "Requesting info for page: 84\n",
      "Got results for page: 84.0\n",
      "Requesting info for page: 85\n",
      "Got results for page: 85.0\n"
     ]
    }
   ],
   "source": [
    "# Request Map for Patriots\n",
    "reqparams = {'api-key':nyt_api_key, 'q':'New England Patriots','begin_date':'20160101', 'end_date':'20161231'}\n",
    "downloadData(articlesearch_url, reqparams, 'New England Patriots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
